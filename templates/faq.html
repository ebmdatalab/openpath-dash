{% extends 'base.html' %}

{% block content %}

<div class="row">

  <h1>Frequently Asked Questions</h1>

</div>

<div class="row">

  <h2 id="access">Where does the data come from and what does it include?</h2>
  
  <p>
    The data is sourced from participating hospital laboratories who carry out pathology tests. 
    Any additional labs wishing to get involved should refer to our <a
      href="https://openpathology.net/blog/get-involved">Get Involved</a> 
    page and get in touch with us.
  </p>
  
  <p>
    We include data on tests requested by practices, for adult patients. 
    Most tests are classified by local test codes which vary by laboratory. 
    We include the most common tests, and those where we have matched 
    codes between several labs. See 
  </p>
  
  <h2 id="access">Who can access the data?</h2>
  
  <p>
    NHS practices and other relevant staff in the regions which have contributed data 
    to the project can access their data on request.
    This includes North Devon, Cornwall, Exeter and Plymouth, with more expected soon. 
    As always, we intend to make our tools public and we hope to be able to do this shortly. 
  </p>
  
  <h2 id="get-involved">How can I see data for my region?</h2>
  
  <p>
    Please refer to our <a
      href="https://openpathology.net/blog/get-involved">Get Involved</a> 
    page. 
  </p>  

  <h2 id="interpret">How do I know if my practice/CCG/lab is performing well?</h2>
  
  <p>
    OpenPathology is akin to an audit and data feedback process. As with all audit and data feedback, 
    such information is best thought of as a measure rather than an indicator, 
    requiring judicious interpretation in the context of population and patient data. 
    Testing rates can be affected by many factors. A few examples may be: population demographics;
    specialisms of a practice, lab or hospital; 
    the range of tests and order sets offered by each lab; and tests required by local care pathways. 
    For example, practices may carry out an apparently high volume of some tests on behalf of 
    a secondary care service or care home.  
   </p>

  <p>
    As such, making a judgement on performance is often largely down to local interpretation. 
    A good question to consider is whether the testing rate is where it is "by design" or "by accident".
  </p>
  
  <p>
    Typically it will be most helpful to compare practices with those using the same laboratory rather 
    than within the same CCG, due to the large influence of laboratory services on tests carried out
    via order sets and order comms systems. In addition, patterns of test results can vary between labs thanks to
    reference ranges and procedures used. 
  </p>
  
  <h2 id="reference-ranges">What are reference ranges?</h2>
  
  <p>
    For many sorts of test the results will be compared with a reference range,
    which is the range of results considered "normal". Where possible we check
    each test result against its reference range and record whether it was
    within, over or under this range.  For more detail on the many problems and
    complexities involved in reference ranges see our blog posts <a
      href="https://openpathology.net/blog/issues-with-reference-ranges-part-1">here</a>,
    <a
      href="https://openpathology.net/blog/issues-with-reference-ranges-part-2">here</a>
    and <a
      href="https://openpathology.net/blog/issues-with-reference-ranges-part-3">here</a>.
  </p>

  <dl>
    <dt>Numeric results Within range / Under range / Over range</dt>
    <dd>
      Selecting this option, you'll see the proportion of results classed as
      Within range ("normal"), or over/under range ("abnormally" high/low), 
      as a proportion of all tests of the selected type with <i>numeric</i> results. 
      Numeric results means that tests were performed successfully and generated a valid result.
      
      However, there are various issues to bear in mind when interpreting this data;
      see next item for more information.
    </dd>
   </dl>
  
  <h2 id="ref-ranges">What are the issues with using reference ranges?</h2>
  
  <dl>
    <dt>Change over time</dt>
    <dd>
      Reference ranges change over time, for example due to new testing equipment, 
      changing guidelines or after a review. We are generally applying 
      only the *latest* reference ranges to all data, except where the 
      laboratory has supplied the within/over/under range flags within the 
      dataset (this currently applies to Plymouth). 
    </dd>
    
  <dl>
    <dt>No ref range</dt>
    <dd>
      For some tests there will be no reference range available. This might be
      because a reference range simply doesn't make sense for this kind of
      test. Or it could be that we haven't been able to obtain a reference
      range for this test from the particular lab involved. Note that
      different labs can have different reference ranges for a given test, 
      and they make different decisions about whether or not to have a reference
      range at all for each test (PSA is one example test where this occurs).
    </dd>

    <dt>Ref range is not valid or applicable</dt>
    <dd>
      At times we may have been supplied with a reference range, 
      but we were unable to interpret it correctly. 
      Sometimes although we have a valid reference range, but not for all
      ages and sexes, or we cannot apply it because of the sex of the patient was unknown 
      (though this usually only applies to neonates which are excluded anyway because we 
      restrict the data to adults only).
    </dd>

    <dt>Insufficient data</dt>
    <dd>
      Sometimes it is not possible to tell whether or not a result falls
      within the reference range. For example, if the reference range is 10-20
      and the result we have is "greater than 18" then we don't know whether
      that result was within or over range. 
    </dd>

  </dl>

  <h2 id="low-numbers">What do the error bars mean?</h2>

  <p>
    To help mitigate potential privacy issues, we apply low number suppression
    to our data. In practice this means that where we have a result count
    between one and five we don't record the exact number and instead just
    record the fact that the count lies in this range.
  </p>

  <p>
    This means that many of our results come with an error range: we know that
    the true value lies between X and Y but we can't say exactly where. In
    charts we display this uncertainty using a coloured band around the line
    where this indicates the minimum and maximum possible values.
  </p>

  <h2 id="lab-list-sizes">How do you calculate patient list sizes for labs?</h2>

  <p>
    Unlike practices or CCGs, labs don't have a patient list and so, strictly
    speaking, there's no such thing as a list size for a lab.  Nevertheless it
    can be useful to have a rough estimate of how many patients are "served" by
    a given lab to use as a denominator. We do this by assigning each practice
    to its "primary" lab, which we define as the lab which processes the
    majority of that practice's potassium tests, with a minimum threshold of 50
    tests in order to filter out noise. A lab's list size is then calculated as
    the sum of the list sizes of all the practices assigned to it.
  </p>

  <h2 id="ccg-list-sizes">Why is the patient list size for my CCG smaller than expected?</h2>

  <p>
    In some cases we have only partial data for a CCG because some practices
    within it use a lab which doesn't (yet) supply us with data. Including
    those practices within the total CCG list size would give a misleading
    picture. For this reason when calculating the total CCG list size we only
    include practices for which we have data (i.e. the practice code occurs at
    least once somewhere in our data).
  </p>

</div>

{% endblock %}
